{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWSnDhyoiPUn",
        "outputId": "16f7fa67-f941-48e7-9a10-a4c60fde0e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.2)\n",
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.11/dist-packages (4.1.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.22.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (0.4.2)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (4.9.1)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from oauth2client) (1.17.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2>=0.9.1->oauth2client) (3.2.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai gspread oauth2client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "_cSowQP5iTkV",
        "outputId": "f22079d7-c782-4148-c01f-df87ce2ab125"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2859e72e-2d51-4f57-b4cc-ecc40d2a4760\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2859e72e-2d51-4f57-b4cc-ecc40d2a4760\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving credentials.json to credentials (1).json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'credentials (1).json': b'{\\n  \"type\": \"service_account\",\\n  \"project_id\": \"rewrite-resume\",\\n  \"private_key_id\": \"fa7969676a72589dcb187cac9729726077d5a615\",\\n  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDmy2zC+ELPxu8i\\\\nyVW0jXX9SKtrowYNeCJ7Po1h6e6CJdMKqnoq1tfXyHfrq13X159aKTG8Wxr3WPLx\\\\nkuKYsBVZVb306gVdvX75L+yu8Kz8Lv4Cs0nUgsoQSeS0ICf5YGGfstTz2AYj8IaE\\\\nPC6kiTujGB6ok6TXCdInIYhab5wwA29O9qMToHz0nUj6/jKfBCRDzaG3hJB1ArPi\\\\nFz6FkLW1lyCekcLrh4h1KowiwpbYTSJgqEOFcUO9RNV3I/0X1g2uvAIAzZIMN1jh\\\\nIccRRYRwekSl4vFZ/8jAqvYPt3bxLU0S3x5Z6VxnQJ0kSWckyPAmqMEjxJnVohmf\\\\nkzOXuNUZAgMBAAECggEAQ9ErvODJdRd+Jmkl63+T16DWajMFsMiHzVI0pjxgrtKh\\\\ngGVWr6bg1tHb1x7MXQPJmes356KXum3jOXQRbI91PoJw5norqH9pw5w+/qrPEe1X\\\\nC4EWZUEnUgD8mKdIR8F3/j7Ez4A/Uak4RbwPcp62rPaF78AutFd47rGuSPC54utY\\\\nh1ZhNYLg9oRxZZpEqgw4QcC9jMCRFjVgX6JvjrJNVEHhqRZaBuSQggBt7wg1BI3b\\\\nWYfdVg4jKLmUE1nLidNPxc1QA6Jvr8e8LGIu8bAlQI/yqZIC6ZySVmnKQqTqYVag\\\\n/suVebKxG4BACOFrl0XH/8cnp2tF15SO4eIFZ2FYlwKBgQD7egcieuiRdeifZWLI\\\\nW2Rg3omjjqAp3LttxIS6LM689jAH1HyL4k8ROxLMfQUI21GjHcbI5QYPhPAOVoAr\\\\nNcNZTaLeYeHODUUfR9fj4PZbHqiU28kJeHo/3ipKA89Ao7Wh0P9t02Sb+Ug4pxMC\\\\n4+ejjgWINbIQC6juwIyxKRcN6wKBgQDq8ime+USjidqEUnIugyD3MbM3NzN8brQS\\\\n2VG8LzQ6qa2liqcVUgV1tejSxv4Iwc7Wu+91e60Cvk6IVHCZ9KVnajkbGa/yd5e0\\\\nEFPOhNyJ7yUv2+fSml/5eynqjbPjdDl/VHNPfgdG1nqs23iFR1RCCld4W+k+vgl8\\\\nWshik1a0CwKBgQC4LTEYgaffENnkE577WmPzxkhL72NCBZWH2QvURojLQAsBURA+\\\\nauq5leg4t79+MxJhQqeZ7pI3v4cJGTUZcHC38PI9qLZ18KYVOMrW7KXBKn0ROL7O\\\\nHtx59j5Gou+hScT21FiemNnwmevZAhQcY8n8sUE/9wOIWOHKql7gSVXHLQKBgDMg\\\\n2/nimRNVzp35KywAEU56HFwpwSSVGs73SBhB1YXmowlhcRbssI97NN2ZvHK/annE\\\\nkEnqzi3IqGJ2rcJzQQOOVDsXjfigGf1viC1rMGs8BcWyf3KPcc9jBC4tBDa9dj3F\\\\nbQqhjIfX6P5xDHtEmIt+oKZqqgmjZYEQaIc7NSUdAoGBALg1y+Mj2oGsR2cXqGqi\\\\ngA3TFOl9usKCNam0+gEWaYnfMPgxDO9zBrANo3Rn2RCAb1GVabizs6UvaYszpDbZ\\\\nFR/Fz0xkw0vuxf5nDUND9hlQH5J15WRfz/CDYbUF7bZUadbikOQGlOdHkBnHUfCZ\\\\nv0PvepyKRvkd8RkX9ikRaHAJ\\\\n-----END PRIVATE KEY-----\\\\n\",\\n  \"client_email\": \"lucylin@rewrite-resume.iam.gserviceaccount.com\",\\n  \"client_id\": \"109955634908622342629\",\\n  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\\n  \"token_uri\": \"https://oauth2.googleapis.com/token\",\\n  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\\n  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/lucylin%40rewrite-resume.iam.gserviceaccount.com\",\\n  \"universe_domain\": \"googleapis.com\"\\n}\\n'}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "nEUa_OgokpjC",
        "outputId": "20f1142e-cf67-41be-bcc9-afc6dca0c923"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1acc4013-9830-42a7-923c-9239171489b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1acc4013-9830-42a7-923c-9239171489b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving jd.txt to jd (1).txt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'jd (1).txt': b'Job Description:\\n1,5+ years of experience in Project Management within IT\\nEnglish \\xe2\\x80\\x93 Upper-Intermediate\\nExperience with status reporting is a must\\nExperience with Agile methodologies\\nExperience with risk management\\nExperience with contracts (like SOW) would be a plus\\n\\nProject Manager\\n \\nMaster of Code Global is specializing in AI-powered conversational experiences. Founded in 2004, we are a US company with development centers in Ukraine (Cherkasy and Kyiv), Canada (Winnipeg, Toronto, Montreal). For over 7 years, we have been working with Conversational AI and also developing an E-commerce product that is successful and growing. Master of Code implemented cutting-edge solutions that have been referenced by Facebook and Apple (integration of Apple Pay into Apple Business Chat, Agent to Chatbot bridge for Messenger, etc.)\\nHere at Master of Code our vision is to make an impact on 1 billion people of the World through amazing digital communication experiences. Along this journey, we aim to create the place and team that people aspire to be a part of.\\nOur clients mainly come from North America, Western Europe, and the Middle East.\\nMoreover, we have our own conversational and e-commerce products co-developed with our partners.\\nOur main domains:\\nConversational Applications\\nWeb and Mobile\\nE-commerce\\n \\n \\nRequired background and skills:\\n1,5+ years of experience in Project Management within IT\\nEnglish \\xe2\\x80\\x93 Upper-Intermediate\\nExperience with status reporting is a must\\nExperience with Agile methodologies\\nExperience with risk management\\nExperience with contracts (like SOW) would be a plus\\nExperience with US-based or English-speaking clients would be a plus\\nExcellent communication and soft skills\\nExcellent presentation skills\\nPassionate about clear project documentation\\nAbility to build strong relationships with Clients and teammates\\nBusiness ethical attitude\\nAnalytical mindset\\nAbility to make and own decisions\\nEager to grow professionally\\n\\nResponsibilities:\\nTake full PM responsibility for the project as expected by the PMI based practices. This includes managing requirements gathering, estimates, scope, schedule, costs, quality, communication, risks, stakeholders expectations and clients satisfaction\\nPeople management of masters on your project(s), shared with Chapter Lead\\nBe a Servant Leader (At MOC leaders serve, facilitate, and empower people and teams for success) \\nRobust risk management on the projects, incl. working with change requests and management of priorities\\nBe proactive and constructive, proposing company\\xe2\\x80\\x99s processes improvements and drive the change where needed\\nDirectly communicate with Clients and Partners (incl. requirements gathering, demoes, progress reports, retrospectives, payments, etc.)\\nProject\\xe2\\x80\\x99s reporting (internal stakeholders and clients), including documentation, performance monitoring, etc.\\n'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AjCuYUalObb"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import gspread\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mto6kH0TlRGW"
      },
      "outputs": [],
      "source": [
        "# === CONFIGURATION ===\n",
        "openai.api_key = \"\"  # Replace with your OpenAI key\n",
        "SPREADSHEET_NAME = \"df3_rewrite\"  # Replace with your actual sheet name\n",
        "JOB_DESCRIPTION_FILE = \"jd.txt\"\n",
        "CREDENTIALS_FILE = \"credentials.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wlGfGZ4lZ9T"
      },
      "outputs": [],
      "source": [
        "# === LOAD JOB DESCRIPTION ===\n",
        "with open(JOB_DESCRIPTION_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    job_description = f.read()\n",
        "\n",
        "# === CONNECT TO GOOGLE SHEETS ===\n",
        "scope = [\"https://spreadsheets.google.com/feeds\", \"https://www.googleapis.com/auth/drive\"]\n",
        "creds = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_FILE, scope)\n",
        "client = gspread.authorize(creds)\n",
        "sheet = client.open(SPREADSHEET_NAME).sheet1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "G1VScffTmKTI",
        "outputId": "f1116a89-6780-4f05-fe67-f5b37ffa689d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Job Description:\\n1,5+ years of experience in Project Management within IT\\nEnglish – Upper-Intermediate\\nExperience with status reporting is a must\\nExperience with Agile methodologies\\nExperience with risk management\\nExperience with contracts (like SOW) would be a plus\\n\\nProject Manager\\n \\nMaster of Code Global is specializing in AI-powered conversational experiences. Founded in 2004, we are a US company with development centers in Ukraine (Cherkasy and Kyiv), Canada (Winnipeg, Toronto, Montreal). For over 7 years, we have been working with Conversational AI and also developing an E-commerce product that is successful and growing. Master of Code implemented cutting-edge solutions that have been referenced by Facebook and Apple (integration of Apple Pay into Apple Business Chat, Agent to Chatbot bridge for Messenger, etc.)\\nHere at Master of Code our vision is to make an impact on 1 billion people of the World through amazing digital communication experiences. Along this journey, we aim to create the place and team that people aspire to be a part of.\\nOur clients mainly come from North America, Western Europe, and the Middle East.\\nMoreover, we have our own conversational and e-commerce products co-developed with our partners.\\nOur main domains:\\nConversational Applications\\nWeb and Mobile\\nE-commerce\\n \\n \\nRequired background and skills:\\n1,5+ years of experience in Project Management within IT\\nEnglish – Upper-Intermediate\\nExperience with status reporting is a must\\nExperience with Agile methodologies\\nExperience with risk management\\nExperience with contracts (like SOW) would be a plus\\nExperience with US-based or English-speaking clients would be a plus\\nExcellent communication and soft skills\\nExcellent presentation skills\\nPassionate about clear project documentation\\nAbility to build strong relationships with Clients and teammates\\nBusiness ethical attitude\\nAnalytical mindset\\nAbility to make and own decisions\\nEager to grow professionally\\n\\nResponsibilities:\\nTake full PM responsibility for the project as expected by the PMI based practices. This includes managing requirements gathering, estimates, scope, schedule, costs, quality, communication, risks, stakeholders expectations and clients satisfaction\\nPeople management of masters on your project(s), shared with Chapter Lead\\nBe a Servant Leader (At MOC leaders serve, facilitate, and empower people and teams for success) \\nRobust risk management on the projects, incl. working with change requests and management of priorities\\nBe proactive and constructive, proposing company’s processes improvements and drive the change where needed\\nDirectly communicate with Clients and Partners (incl. requirements gathering, demoes, progress reports, retrospectives, payments, etc.)\\nProject’s reporting (internal stakeholders and clients), including documentation, performance monitoring, etc.\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMf4GQqKoYL1",
        "outputId": "498eda84-5bd1-4e64-c9c0-a1307e16da8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 239, in _attempt_to_pin_criterion\n",
            "    criteria = self._get_updated_criteria(candidate)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 230, in _get_updated_criteria\n",
            "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 148, in _add_to_criteria\n",
            "    matches = self._p.find_matches(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/provider.py\", line 232, in find_matches\n",
            "    return self._factory.find_candidates(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 450, in find_candidates\n",
            "    return self._iter_found_candidates(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 341, in _iter_found_candidates\n",
            "    _get_installed_candidate(),\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 287, in _get_installed_candidate\n",
            "    if not specifier.contains(installed_dist.version, prereleases=True):\n",
            "                              ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 175, in version\n",
            "    return parse_version(self._dist.version)\n",
            "                         ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 632, in version\n",
            "    return self.metadata['Version']\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/metadata/__init__.py\", line 617, in metadata\n",
            "    return _adapters.Message(email.message_from_string(text))\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/__init__.py\", line 37, in message_from_string\n",
            "    return Parser(*args, **kws).parsestr(s)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 67, in parsestr\n",
            "    return self.parse(StringIO(text), headersonly=headersonly)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/parser.py\", line 56, in parse\n",
            "    feedparser.feed(data)\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 174, in feed\n",
            "    self._call_parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 178, in _call_parse\n",
            "    self._parse()\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 238, in _parsegen\n",
            "    self._parse_headers(headers)\n",
            "  File \"/usr/lib/python3.11/email/feedparser.py\", line 486, in _parse_headers\n",
            "    self._cur.set_raw(*self.policy.header_source_parse(lastvalue))\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/email/_policybase.py\", line 311, in header_source_parse\n",
            "    return (name, value.rstrip('\\r\\n'))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1477, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 695, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 645, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 728, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 425, in _extract_from_extended_frame_gen\n",
            "    result.append(FrameSummary(\n",
            "                  ^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 261, in __init__\n",
            "    def __init__(self, filename, lineno, name, *, lookup_line=True,\n",
            "\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtYKI9lVqpQx"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTbVSXP_nxNS"
      },
      "outputs": [],
      "source": [
        "# === PROCESS CVs ===\n",
        "rows = sheet.get_all_values()\n",
        "\n",
        "for i, row in enumerate(rows[1:], start=2):  # Skip header row\n",
        "    original_cv = row[0].strip()  # Column A → Original CV\n",
        "    existing_rewrite = row[1].strip() if len(row) > 1 else \"\"  # Column B → Already rewritten?\n",
        "\n",
        "    if not original_cv or existing_rewrite:\n",
        "        continue  # Skip empty or already rewritten rows\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a real human. Don't put project manager in the first sentence. Rewrite the following candidate's CV to better match the job description below. Focus on emphasizing matching skills, experience, and qualifications. Keep it realistic, concise, and professional. Keep it sound like a real person.\n",
        "\n",
        "Job Description:\n",
        "{job_description}\n",
        "\n",
        "Candidate CV:\n",
        "{original_cv}\n",
        "\n",
        "Rewritten CV:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",  # ✅ Use \"gpt-4\" or \"gpt-3.5-turbo\" (cheaper, faster)\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.4,\n",
        "            max_tokens=1000,  # ✅ Can be increased if your CVs are long\n",
        "        )\n",
        "        rewritten_cv = response['choices'][0]['message']['content']\n",
        "        sheet.update_cell(i, 2, rewritten_cv)  # Column B = rewritten CV\n",
        "        print(f\"✅ Row {i} updated.\")\n",
        "        time.sleep(20)  # ✅ To avoid OpenAI rate limits\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error at row {i}: {e}\")\n",
        "        # Optional: Log error to column C\n",
        "        # sheet.update_cell(i, 3, str(e))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
